{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-12-09T08:48:06.195468Z","iopub.status.busy":"2021-12-09T08:48:06.194966Z","iopub.status.idle":"2021-12-09T08:48:06.261060Z","shell.execute_reply":"2021-12-09T08:48:06.260485Z","shell.execute_reply.started":"2021-12-09T08:48:06.195338Z"},"trusted":true},"outputs":[],"source":["import numpy as np #导入NumPy数学工具箱\n","import pandas as pd #导入Pandas数据处理工具箱\n","# 读入数据并显示前面几行的内容，这是为了确保我们的文件读入正确性\n","# 示例代码是在Kaggle中数据集中读入文件，如果在本机中需要指定具体本地路径\n","df_ads = pd.read_csv('../input/advertising-simple-dataset/advertising.csv')\n","df_ads.head()"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:06.262801Z","iopub.status.busy":"2021-12-09T08:48:06.262476Z","iopub.status.idle":"2021-12-09T08:48:06.281789Z","shell.execute_reply":"2021-12-09T08:48:06.280647Z","shell.execute_reply.started":"2021-12-09T08:48:06.262774Z"},"trusted":true},"outputs":[],"source":["X = np.array(df_ads) # 构建特征集，含全部特征\n","X = np.delete(X, [3], axis = 1) # 删除掉标签\n","y = np.array(df_ads.sales) #构建标签集，销售金额\n","print (\"张量X的阶:\",X.ndim)\n","print (\"张量X的形状:\", X.shape)\n","print (X)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:06.285654Z","iopub.status.busy":"2021-12-09T08:48:06.285402Z","iopub.status.idle":"2021-12-09T08:48:06.294010Z","shell.execute_reply":"2021-12-09T08:48:06.293350Z","shell.execute_reply.started":"2021-12-09T08:48:06.285626Z"},"trusted":true},"outputs":[],"source":["y = y.reshape(-1,1) #通过reshape函数把向量转换为矩阵，-1就是len(y),返回样本个数\n","print (\"张量y的形状:\", y.shape)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:06.295759Z","iopub.status.busy":"2021-12-09T08:48:06.294921Z","iopub.status.idle":"2021-12-09T08:48:07.384706Z","shell.execute_reply":"2021-12-09T08:48:07.383823Z","shell.execute_reply.started":"2021-12-09T08:48:06.295713Z"},"trusted":true},"outputs":[],"source":["# 将数据集进行80%（训练集）和20%（验证集）的分割\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                   test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.387984Z","iopub.status.busy":"2021-12-09T08:48:07.387656Z","iopub.status.idle":"2021-12-09T08:48:07.394446Z","shell.execute_reply":"2021-12-09T08:48:07.393382Z","shell.execute_reply.started":"2021-12-09T08:48:07.387942Z"},"trusted":true},"outputs":[],"source":["def scaler(train, test): # 定义归一化函数 ，进行数据压缩    \n","    # 数据的压缩\n","    min = train.min(axis=0) # 训练集最小值\n","    max = train.max(axis=0) # 训练集最大值\n","    gap = max - min # 最大值和最小值的差\n","    train -= min # 所有数据减最小值\n","    train /= gap # 所有数据除以大小值差\n","    test -= min #把训练集最小值应用于测试集\n","    test /= gap #把训练集大小值差应用于测试集\n","    return train, test # 返回压缩后的数据"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.396466Z","iopub.status.busy":"2021-12-09T08:48:07.396013Z","iopub.status.idle":"2021-12-09T08:48:07.406190Z","shell.execute_reply":"2021-12-09T08:48:07.405184Z","shell.execute_reply.started":"2021-12-09T08:48:07.396431Z"},"trusted":true},"outputs":[],"source":["def min_max_gap(train): # 计算训练集最大，最小值以及他们的差，用于后面反归一化过程\n","    min = train.min(axis=0) # 训练集最小值\n","    max = train.max(axis=0) # 训练集最大值\n","    gap = max - min # 最大值和最小值的差\n","    return min, max, gap\n","    \n","y_min, y_max, y_gap = min_max_gap(y_train)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.408070Z","iopub.status.busy":"2021-12-09T08:48:07.407799Z","iopub.status.idle":"2021-12-09T08:48:07.418994Z","shell.execute_reply":"2021-12-09T08:48:07.418288Z","shell.execute_reply.started":"2021-12-09T08:48:07.408037Z"},"trusted":true},"outputs":[],"source":["X_train_original = X_train.copy() # 保留一份训练集数据副本，用于对要预测数据归一化"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.420710Z","iopub.status.busy":"2021-12-09T08:48:07.420482Z","iopub.status.idle":"2021-12-09T08:48:07.430008Z","shell.execute_reply":"2021-12-09T08:48:07.429331Z","shell.execute_reply.started":"2021-12-09T08:48:07.420683Z"},"trusted":true},"outputs":[],"source":["X_train,X_test = scaler(X_train,X_test) # 对特征归一化\n","y_train,y_test = scaler(y_train,y_test) # 对标签也归一化"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.431307Z","iopub.status.busy":"2021-12-09T08:48:07.431024Z","iopub.status.idle":"2021-12-09T08:48:07.455217Z","shell.execute_reply":"2021-12-09T08:48:07.454320Z","shell.execute_reply.started":"2021-12-09T08:48:07.431267Z"},"trusted":true},"outputs":[],"source":["x0_train = np.ones((len(X_train),1)) # 构造X_train长度的全1数组配合对Bias的点积\n","X_train = np.append(x0_train, X_train, axis=1) #把X增加一系列的1\n","x0_test = np.ones((len(X_test),1)) # 构造X_test长度的全1数组配合对Bias的点积\n","X_test = np.append(x0_test, X_test, axis=1) #把X增加一系列的1\n","print (\"张量X的形状:\", X_train.shape)\n","print (X_train)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.456875Z","iopub.status.busy":"2021-12-09T08:48:07.456561Z","iopub.status.idle":"2021-12-09T08:48:07.466564Z","shell.execute_reply":"2021-12-09T08:48:07.465588Z","shell.execute_reply.started":"2021-12-09T08:48:07.456840Z"},"trusted":true},"outputs":[],"source":["def loss_function(X, y, W): # 手工定义一个MSE均方误差函数,W此时是一个向量\n","    y_hat = X.dot(W.T) # 点积运算 h(x)=w_0*x_0 + w_1*x_1 + w_2*x_2 + w_3*x_3    \n","    loss = y_hat.reshape((len(y_hat),1))-y # 中间过程,求出当前W和真值的差异\n","    cost = np.sum(loss**2)/(2*len(X)) # 这是平方求和过程, 均方误差函数的代码实现\n","    return cost # 返回当前模型的均方误差值"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.468392Z","iopub.status.busy":"2021-12-09T08:48:07.468164Z","iopub.status.idle":"2021-12-09T08:48:07.479654Z","shell.execute_reply":"2021-12-09T08:48:07.478918Z","shell.execute_reply.started":"2021-12-09T08:48:07.468364Z"},"trusted":true},"outputs":[],"source":["def gradient_descent(X, y, W, lr, iterations): # 定义梯度下降函数\n","    l_history = np.zeros(iterations) # 初始化记录梯度下降过程中损失的数组\n","    W_history = np.zeros((iterations,len(W))) # 初始化权重数组 \n","    for iter in range(iterations): # 进行梯度下降的迭代，就是下多少级台阶\n","        y_hat = X.dot(W.T) # 这个是向量化运行实现的假设函数   \n","        loss = y_hat.reshape((len(y_hat),1))-y # 中间过程, y_hat和y真值的差\n","        derivative_W = X.T.dot(loss)/len(X) #求出多项式的梯度向量\n","        derivative_W = derivative_W.reshape(len(W)) \n","        W = W - lr*derivative_W # 结合下降速率更新权重\n","        l_history[iter] = loss_function(X, y, W) # 损失的历史记录 \n","        W_history[iter] = W # 梯度下降过程中权重的历史记录\n","    return l_history, W_history # 返回梯度下降过程数据"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.481771Z","iopub.status.busy":"2021-12-09T08:48:07.481265Z","iopub.status.idle":"2021-12-09T08:48:07.493586Z","shell.execute_reply":"2021-12-09T08:48:07.492190Z","shell.execute_reply.started":"2021-12-09T08:48:07.481727Z"},"trusted":true},"outputs":[],"source":["#首先确定参数的初始值\n","iterations = 300; # 迭代300次\n","alpha = 0.15; #学习速率设为0.15\n","weight = np.array([0.5,1,1,1]) # 权重向量，w[0] = bias\n","#计算一下初始值的损失\n","print ('当前损失：',loss_function(X_train, y_train, weight))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.495844Z","iopub.status.busy":"2021-12-09T08:48:07.495331Z","iopub.status.idle":"2021-12-09T08:48:07.508230Z","shell.execute_reply":"2021-12-09T08:48:07.507138Z","shell.execute_reply.started":"2021-12-09T08:48:07.495800Z"},"trusted":true},"outputs":[],"source":["# 定义线性回归模型\n","def linear_regression(X, y, weight, alpha, iterations): \n","    loss_history, weight_history = gradient_descent(X, y, \n","                                                    weight, \n","                                                    alpha, iterations)\n","    print(\"训练最终损失:\", loss_history[-1]) # 打印最终损失\n","    y_pred = X.dot(weight_history[-1]) # 进行预测\n","    traning_acc = 100 - np.mean(np.abs(y_pred - y))*100 # 计算准确率\n","    print(\"线性回归训练准确率: {:.2f}%\".format(traning_acc))  # 打印准确率\n","    return loss_history, weight_history # 返回训练历史记录"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.511486Z","iopub.status.busy":"2021-12-09T08:48:07.510577Z","iopub.status.idle":"2021-12-09T08:48:07.535554Z","shell.execute_reply":"2021-12-09T08:48:07.534828Z","shell.execute_reply.started":"2021-12-09T08:48:07.511451Z"},"trusted":true},"outputs":[],"source":["# 调用刚才定义的线性回归模型\n","loss_history, weight_history = linear_regression(X_train, y_train,\n","                           weight, alpha, iterations) #训练机器"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.537836Z","iopub.status.busy":"2021-12-09T08:48:07.536792Z","iopub.status.idle":"2021-12-09T08:48:07.548961Z","shell.execute_reply":"2021-12-09T08:48:07.548351Z","shell.execute_reply.started":"2021-12-09T08:48:07.537769Z"},"trusted":true},"outputs":[],"source":["print(\"权重历史记录：\", weight_history)\n","print(\"损失历史记录：\", loss_history)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-12-09T08:48:07.550782Z","iopub.status.busy":"2021-12-09T08:48:07.549962Z","iopub.status.idle":"2021-12-09T08:48:07.568336Z","shell.execute_reply":"2021-12-09T08:48:07.567653Z","shell.execute_reply.started":"2021-12-09T08:48:07.550746Z"},"trusted":true},"outputs":[],"source":["X_plan = [250,50,50] # 要预测的X特征数据\n","X_train,X_plan = scaler(X_train_original,X_plan) # 对预测数据也要归一化缩放\n","X_plan = np.append([1], X_plan ) # 加一个哑特征X0 = 1\n","y_plan = np.dot(weight_history[-1],X_plan) # [-1] 即模型收敛时的权重\n","# 对预测结果要做反向缩放，才能得到与原始广告费用对应的预测值\n","y_value = y_plan*y_gap + y_min # y_gap是当前y_train中最大值和最小值的差，y_min是最小值\n","print (\"预计商品销售额： \",y_value, \"千元\") "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"0.0.0"}},"nbformat":4,"nbformat_minor":4}
